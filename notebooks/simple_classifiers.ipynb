{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Classifiers and preprocessing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing of the data and spliting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next, we will import the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = '../data/chartex_final.csv'\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fill all missing data with the expectation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['track_name', 'artist', 'album', 'id', 'song_name', 'artist_name'], axis = 1, errors = 'ignore')\n",
    "means = df.mean()\n",
    "df.fillna(value=means, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next, we will split the target feature (track_pop) from the rest of the features and split to train and test sets. In addition, we will replace track_pop with a new binary feature that indicate if a track is popular according to track_pop and threshold of our choice and it will be out target feature for **classification**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = df.drop(['artist_pop', 'number_of_videos', 'number_of_videos_last_14days', 'total_likes_count', 'key',], axis = 1, errors = 'ignore')\n",
    "columns = df.columns\n",
    "\n",
    "X, y = df.drop(['track_pop'], axis=1, errors = 'ignore').values,  df['track_pop'].values\n",
    "\n",
    "#for classification:\n",
    "# 50 is the threshold.\n",
    "y = (y > 50).astype('int32')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = SEED, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, column in enumerate(columns):\n",
    "    if i == 0:\n",
    "        print(f'Target: {column}')\n",
    "    else:\n",
    "        print(f'#{i-1} : {column}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's investigate a bit the train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train:\")\n",
    "print(\"#samples in train:\", y_train.shape[0])\n",
    "print(\"#popular samples in train:\", y_train.sum().item()/y_train.shape[0])\n",
    "\n",
    "print(\"\\nTest:\")\n",
    "print(\"#samples in test:\", y_test.shape[0])\n",
    "print(\"#popular samples in test:\", y_test.sum().item()/y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def print_accuracy(model, X_train, X_test, y_train, y_test):\n",
    "    y_pred = model.predict(X_train)\n",
    "    print(\"train accuracy =\",(y_train == y_pred).mean())\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"test accuracy =\",(y_test == y_pred).mean())\n",
    "\n",
    "splitted_data = (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to train the models.\n",
    "\n",
    "We will start with Logistic regression with l2 regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "logit_lin_l2_model = linear_model.LogisticRegression(C = 5)\n",
    "logit_lin_l2_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_accuracy(logit_lin_l2_model, *splitted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model is just better than random classifier.\n",
    "\n",
    "Considering that we used the model on the raw data it is not suprising that the model did bad job in predicting the popularity.\n",
    "\n",
    "Let's try decision trees!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put regularization by forcing all leaves in the tree to have at least 10 samples from the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "tree_model = tree.DecisionTreeClassifier(criterion = 'entropy', min_samples_split = 10)\n",
    "\n",
    "tree_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tree.export_text(tree_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_accuracy(tree_model, *splitted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Has we can see from the result, the model suffers from overfitting. So, let's do cross validation on min_samples_split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "list_of_mins = [10,50,100,300,500,1000]\n",
    "accuracy_per_value = []\n",
    "\n",
    "for min_leaf in list_of_mins:\n",
    "    tree_model = tree.DecisionTreeClassifier(criterion = 'entropy', min_samples_split = min_leaf)\n",
    "    cv_result = cross_validate(tree_model, X_train, y_train, cv=3, scoring= ('accuracy'))\n",
    "    accuracy_per_value.append(cv_result['test_score'].mean())\n",
    "\n",
    "optim_min = list_of_mins[np.argmax(accuracy_per_value)]\n",
    "tree_model = tree.DecisionTreeClassifier(criterion = 'entropy', min_samples_split = optim_min)\n",
    "tree_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then, the accuracies of the model with the optimal min_samples_split is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_accuracy(tree_model, *splitted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not a good result. We need to remember that we are still working on the row data and didn't do any feature mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost classifier:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's play with AdaBoost a bit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#the base model is stump - decision tree with maximal depth of 1.\n",
    "adaboost_model = AdaBoostClassifier(n_estimators=50, learning_rate=20)\n",
    "adaboost_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_accuracy(adaboost_model, *splitted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if Cross validation can help it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [10, 25, 50]\n",
    "lr = [0.01, 0.1, 1]\n",
    "accuracy_per_value = []\n",
    "\n",
    "for n_estimator in estimators:\n",
    "    for rate in lr:\n",
    "        adaboost_model = AdaBoostClassifier(n_estimators=n_estimator, learning_rate= rate)\n",
    "        cv_result = cross_validate(adaboost_model, X_train, y_train, cv=3, scoring= ('accuracy'))\n",
    "        accuracy_per_value.append(cv_result['test_score'].mean())\n",
    "\n",
    "optim_idx = np.argmax(accuracy_per_value)\n",
    "adaboost_model = AdaBoostClassifier(n_estimators= estimators[optim_idx//len(lr)], learning_rate= lr[optim_idx%len(lr)])\n",
    "adaboost_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_accuracy(adaboost_model, *splitted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how many features we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "output_dim = 2\n",
    "train_samples = X_train.shape[0]\n",
    "\n",
    "print(\"input dim:\", input_dim)\n",
    "print(\"number of train samples:\", train_samples)\n",
    "print(\"number of test samples:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype = torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype = torch.long)\n",
    "\n",
    "X_test = torch.tensor(X_test, dtype = torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype = torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "num_epochs = 100\n",
    "num_batches = train_samples//batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple MLP:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by checking if it is possible to overfit the MLP on small subset of the training set: (in order to see if the implementation of trainer and dataIterator module are good):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = nn.Sequential(\n",
    "    nn.BatchNorm1d(input_dim),\n",
    "    nn.Linear(input_dim, 64),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(64, 32),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(32, output_dim),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "print(mlp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(mlp_model.parameters(), lr=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.LinearLR(optimizer,start_factor=1.0,end_factor=1e-4,total_iters=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.trainer import trainer\n",
    "\n",
    "mlp_trainer = trainer(mlp_model,optimizer,loss_fn,num_epochs,batch_size,True)\n",
    "\n",
    "loss_list, accuracy_list = mlp_trainer.fit(X_train=X_train,y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(15,5))\n",
    "\n",
    "axs[0].plot(range(num_epochs), loss_list)\n",
    "axs[0].set_xlabel('epoch')\n",
    "axs[0].set_ylabel('loss')\n",
    "\n",
    "axs[1].plot(range(num_epochs), accuracy_list)\n",
    "axs[1].set_xlabel('epoch')\n",
    "axs[1].set_ylabel('accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlp_model(X_test)\n",
    "test_accuracy = (torch.argmax(y_pred,dim=1) == y_test).sum().item() / X_test.shape[0]\n",
    "print(f'Test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice a bit of overfitting because while the train accuracy is above above 74%, the test accuracy is just above 60%.\n",
    "\n",
    "In addition, it seems that the learning rate is not correct because the decrease in the loss is very small, preventing the model to learn well.\n",
    "\n",
    "We will next do cross validation on few hyperparameters in order to get the better model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation for MLP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from src.cross_val import setConfigure, crossValidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from src.trainer import trainer\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "kf = KFold(2,shuffle=True, random_state=SEED)\n",
    "\n",
    "configures = setConfigure({'lr':[1e-3,1e-4]})\n",
    "\n",
    "results = []\n",
    "for config in configures:\n",
    "    mlp_model = nn.Sequential(\n",
    "        nn.BatchNorm1d(input_dim),\n",
    "        nn.Linear(input_dim, 64),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Linear(64, 32),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Linear(32, output_dim),\n",
    "        nn.Softmax(dim=1)\n",
    "    )\n",
    "    print(f'The configuration is {config}:')\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(mlp_model.parameters(), config['lr'])\n",
    "    scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, total_iters=10)\n",
    "\n",
    "    mlp_trainer = trainer(mlp_model,optimizer,loss_fn,num_epochs,batch_size,True)\n",
    "    results.append(crossValidate(mlp_trainer, X_train, y_train, kf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.plot_utils import plotCV\n",
    "\n",
    "plotCV(results, configures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Others:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the entire model:\n",
    "#torch.save(model, \"my_model.pickle\")\n",
    "#model = torch.load(\"my_model.pickle\")\n",
    "\n",
    "#Save only the weights: (recommended)\n",
    "#torch.save(model.state_dict(), \"my_model.pickle\")\n",
    "#model = nn.Sequential(...)\n",
    "#model.load_state_dict(torch.load(\"my_model.pickle\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
