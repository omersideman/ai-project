{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Audio Features and Downloading Audio Files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from src.utils.audio_utils import dl_and_extract_features\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction and download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"../data/csv_files/chartex_final.csv\"\n",
    "audio_dir = \"../data/audio_wav\"\n",
    "\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_extract(df, start_index, end_index):\n",
    "    for i in range(start_index, end_index):\n",
    "        print(f'Processing track {i+1} of {len(df)}')\n",
    "        track_data = df.iloc[i]\n",
    "        features = dl_and_extract_features(track_data)\n",
    "        if not features:\n",
    "            print(\n",
    "                f'No features found for track {i+start_index} of {len(df)}, skipping...')\n",
    "            continue\n",
    "        # add features to dataframe\n",
    "        for feature_names in features.keys():\n",
    "            df.loc[i, feature_names] = features[feature_names]\n",
    "        # save dataframe\n",
    "        df.to_csv(\"../data/audio_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to skip songs that have been previously downloaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded_songs = os.listdir('../data/audio_wav/')\n",
    "num_of_songs = len(df.index)\n",
    "\n",
    "for i in range(num_of_songs):\n",
    "    curr_song = df.iloc[i]\n",
    "    if not curr_song['id'] + '.wav' in downloaded_songs:\n",
    "        batch_extract(df, i, i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We couldn't download most of those missing songs. We will ignore them.\n",
    "\n",
    "Next, we will convert the audio files from MP4 format to MP3 format in order to be able to use it in the torchaudio library:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"../data/audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "for song in tqdm(downloaded_songs):\n",
    "    song_path = \"../data/audio_wav/\" + song\n",
    "    conv_song_path = \"../data/audio/\" + song[:-4] + \".mp3\"\n",
    "    ffmpeg_command = f\"ffmpeg -i {song_path} -vn -acodec libmp3lame -q:a 4 -ar 22050 {conv_song_path}\"\n",
    "\n",
    "    subprocess.run(ffmpeg_command, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the dataset:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's finish by creating the .csv of the dataset, using the threshold of $5e5$. We will first drop all features that the model cannot infer from the audio and the new features we created:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_songs = [song[:-4] for song in os.listdir('../data/audio/')]\n",
    "\n",
    "\n",
    "df['viral'] = (df['number_of_videos'] > 5e5).astype('int32')\n",
    "df.drop(['track_name', 'track_pop', 'artist', 'artist_pop', 'album', 'number_of_videos'\n",
    "        'time_signature', 'artist_name', 'total_likes_count', 'number_of_videos',\n",
    "         'chroma_stft', 'rmse', 'spec_cent', 'spec_bw', 'rolloff', 'zcr', 'mfcc'], axis=1, errors='ignore', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and delete all songs from the dataframe that we couldn't download:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df[\"id\"].isin(converted_songs))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that duration_ms is not correct and thus we will fix it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "\n",
    "\n",
    "def get_duration_ffmpeg(file_path):\n",
    "    probe = ffmpeg.probe(file_path)\n",
    "    stream = next(\n",
    "        (stream for stream in probe['streams'] if stream['codec_type'] == 'audio'), None)\n",
    "    duration = float(stream['duration'])\n",
    "    return duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3915/3915 [01:45<00:00, 36.97it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(df.index):\n",
    "    df.loc[i, 'duration_ms'] = get_duration_ffmpeg(\n",
    "        '../data/audio/' + df.loc[i, 'id'] + '.mp3') * 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we will delete all songs that are shorter than 30 seconds and longer than 5 minutes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['duration_ms'] < 5*60*1000) & (df['duration_ms'] >= 30*1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/metadata.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
